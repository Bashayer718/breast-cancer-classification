{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing for the augmentation experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Check Class Balance in Original Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "normal: 266 images\n",
      "benign: 891 images\n",
      "malignant: 421 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_class_balance(directory):\n",
    "    \"\"\"\n",
    "    Check the number of images in each class subdirectory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing class subfolders.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with class names as keys and the number of images as values.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "\n",
    "    # Iterate through all class subdirectories\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):  # Ensure it's a folder\n",
    "            # Count the number of files (excluding hidden files)\n",
    "            num_files = len([f for f in os.listdir(class_path) if not f.startswith('.')])\n",
    "            class_counts[class_name] = num_files\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "# Specify the directory to check\n",
    "target_dir = \"Data/Dataset_BUSI_with_GT\"\n",
    "\n",
    "# Check class balance\n",
    "class_balance = check_class_balance(target_dir)\n",
    "\n",
    "# Display the results\n",
    "print(\"Class Distribution:\")\n",
    "for class_name, count in class_balance.items():\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Generating Image and Mask Augmentation for Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Augmentation function with synchronized transformations\n",
    "def synchronized_transform(image, masks, resize=256, crop_size=224, degrees=70, p_flip=0.5):\n",
    "    seed = random.randint(0, 10000)\n",
    "\n",
    "    # Resize image and masks\n",
    "    image = F.resize(image, resize)\n",
    "    masks = [F.resize(mask, resize) for mask in masks]\n",
    "\n",
    "    # Random rotation (shared angle)\n",
    "    random.seed(seed)\n",
    "    angle = random.uniform(-degrees, degrees)\n",
    "    image = F.rotate(image, angle, fill=0)\n",
    "    masks = [F.rotate(mask, angle, fill=0) for mask in masks]\n",
    "\n",
    "    # Center crop\n",
    "    image = F.center_crop(image, crop_size)\n",
    "    masks = [F.center_crop(mask, crop_size) for mask in masks]\n",
    "\n",
    "    # Random horizontal flip\n",
    "    random.seed(seed)\n",
    "    if random.random() < p_flip:\n",
    "        image = F.hflip(image)\n",
    "        masks = [F.hflip(mask) for mask in masks]\n",
    "\n",
    "    # Convert to tensor\n",
    "    image = F.to_tensor(image)\n",
    "    masks = [F.to_tensor(mask) for mask in masks]\n",
    "\n",
    "    return image, masks\n",
    "\n",
    "# Prepare the dataset object\n",
    "def prepare_dataset(data_dir, categories):\n",
    "    dataset = []\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        for file_name in os.listdir(category_dir):\n",
    "            if '_mask' not in file_name:  # Check for base image\n",
    "                image_path = os.path.join(category_dir, file_name)\n",
    "                base_name = os.path.splitext(file_name)[0]\n",
    "                mask_paths = [os.path.join(category_dir, f) for f in os.listdir(category_dir)\n",
    "                              if base_name in f and '_mask' in f]\n",
    "                dataset.append((image_path, mask_paths, category))\n",
    "    return dataset\n",
    "\n",
    "# Augmentation target counts\n",
    "augmentation_target = {\n",
    "    \"malignant\": 25,  # Additional images needed\n",
    "    \"normal\": 179      # Additional images needed\n",
    "}\n",
    "\n",
    "def augment_class(dataset, class_name, additional_samples, output_dir):\n",
    "    class_samples = [data for data in dataset if data[2] == class_name]\n",
    "\n",
    "    augmented_count = 0\n",
    "    while augmented_count < additional_samples:\n",
    "        for img_path, mask_paths, _ in class_samples:\n",
    "            if augmented_count >= additional_samples:\n",
    "                break\n",
    "\n",
    "            # Load the image and masks\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            masks = [Image.open(mask_path).convert(\"L\") for mask_path in mask_paths]\n",
    "\n",
    "            # Apply synchronized transformations to image and masks\n",
    "            augmented_image, augmented_masks = synchronized_transform(image, masks)\n",
    "\n",
    "            # Save the augmented image and masks\n",
    "            unique_id = str(uuid.uuid4())\n",
    "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            output_class_dir = os.path.join(output_dir, class_name)\n",
    "            os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "            # Save augmented image\n",
    "            img_save_path = os.path.join(output_class_dir, f\"{base_name}_aug_{unique_id}.png\")\n",
    "            F.to_pil_image(augmented_image).save(img_save_path)\n",
    "\n",
    "            # Save augmented masks\n",
    "            for i, mask in enumerate(augmented_masks):\n",
    "                mask_save_path = os.path.join(output_class_dir, f\"{base_name}_mask_aug_{unique_id}_{i}.png\")\n",
    "                F.to_pil_image(mask).save(mask_save_path)\n",
    "\n",
    "            augmented_count += 1\n",
    "\n",
    "# Directories\n",
    "original_dir = \"Data/Dataset_BUSI_with_GT\"\n",
    "augmented_dir = \"Augmented_data\"\n",
    "categories = ['normal', 'benign', 'malignant']\n",
    "\n",
    "# Prepare the dataset\n",
    "dataset = prepare_dataset(original_dir, categories)\n",
    "\n",
    "# Augment the minority classes\n",
    "for class_name, additional_samples in augmentation_target.items():\n",
    "    print(f\"Augmenting class '{class_name}' to add {additional_samples} samples...\")\n",
    "    augment_class(dataset, class_name, additional_samples, augmented_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Check Class Balance in Augmented Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_class_balance(directory):\n",
    "    \"\"\"\n",
    "    Check the number of images in each class subdirectory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing class subfolders.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with class names as keys and the number of images as values.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "\n",
    "    # Iterate through all class subdirectories\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):  # Ensure it's a folder\n",
    "            # Count the number of files (excluding hidden files)\n",
    "            num_files = len([f for f in os.listdir(class_path) if not f.startswith('.')])\n",
    "            class_counts[class_name] = num_files\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "# Specify the directory to check\n",
    "target_dir = \"Augmented_data\"\n",
    "\n",
    "# Check class balance\n",
    "class_balance = check_class_balance(target_dir)\n",
    "\n",
    "# Display the results\n",
    "print(\"Class Distribution:\")\n",
    "for class_name, count in class_balance.items():\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Renaming Augmented Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the dataset directory (containing 'normal', 'benign', 'malignant')\n",
    "dataset_dir = \"Augmented_data\"\n",
    "\n",
    "# Categories to process\n",
    "categories = ['normal', 'benign', 'malignant']\n",
    "\n",
    "# Process each category\n",
    "for category in categories:\n",
    "    category_path = os.path.join(dataset_dir, category)\n",
    "    if not os.path.exists(category_path):\n",
    "        print(f\"Warning: {category_path} does not exist. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Get all files in the category directory\n",
    "    all_files = sorted(os.listdir(category_path))\n",
    "\n",
    "    # Initialize counters for renaming\n",
    "    aug_counter = {}\n",
    "\n",
    "    print(f\"Processing category: {category}\")\n",
    "\n",
    "    # Process each file in the directory\n",
    "    for file_name in all_files:\n",
    "        if \"_aug_\" in file_name and \"mask\" not in file_name:  # Augmented images without masks\n",
    "            # Extract the base name before the unique ID\n",
    "            base_name = file_name.split(\"_aug_\")[0]\n",
    "            \n",
    "            # Increment the counter for this base name\n",
    "            if base_name not in aug_counter:\n",
    "                aug_counter[base_name] = 0\n",
    "            else:\n",
    "                aug_counter[base_name] += 1\n",
    "            \n",
    "            # Generate the new file name for the image\n",
    "            new_image_name = f\"{base_name}_aug_{aug_counter[base_name]}.png\"\n",
    "            \n",
    "            # Generate the expected mask file name\n",
    "            unique_id = file_name.split(\"_aug_\")[1].split(\".png\")[0]\n",
    "            mask_name = f\"{base_name}_mask_aug_{unique_id}_0.png\"\n",
    "            \n",
    "            # Generate the new file name for the mask\n",
    "            new_mask_name = f\"{base_name}_aug_{aug_counter[base_name]}_mask.png\"\n",
    "            \n",
    "            # Rename the image\n",
    "            image_path = os.path.join(category_path, file_name)\n",
    "            new_image_path = os.path.join(category_path, new_image_name)\n",
    "            os.rename(image_path, new_image_path)\n",
    "            print(f\"Renamed {file_name} to {new_image_name}\")\n",
    "            \n",
    "            # Rename the mask if it exists\n",
    "            mask_path = os.path.join(category_path, mask_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                new_mask_path = os.path.join(category_path, new_mask_name)\n",
    "                os.rename(mask_path, new_mask_path)\n",
    "                print(f\"Renamed {mask_name} to {new_mask_name}\")\n",
    "            else:\n",
    "                print(f\"Warning: No matching mask found for {file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing for the Intersection experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Processing Images with Intersection Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "from PIL import Image\n",
    "\n",
    "def process_image_and_masks(image_path, mask_paths, output_dir, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Process an image and its corresponding masks to create an intersection mask and apply it to the image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        mask_paths (list of str): List of paths to the masks corresponding to the image.\n",
    "        output_dir (str): Directory to save the processed images.\n",
    "        target_size (tuple): Target size for resizing images and masks (width, height).\n",
    "\n",
    "    Returns:\n",
    "        None: Saves the processed image with the intersection mask applied.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Ensure image is RGB\n",
    "        image = image.resize(target_size)  # Resize to target size\n",
    "        image_tensor = ToTensor()(image)  # Convert to tensor with shape (3, H, W)\n",
    "\n",
    "        # Load and concatenate the masks\n",
    "        masks = []\n",
    "        for mask_path in mask_paths:\n",
    "            mask = Image.open(mask_path).convert(\"L\")  # Ensure mask is grayscale\n",
    "            mask = mask.resize(target_size)  # Resize to target size\n",
    "            mask_tensor = ToTensor()(mask)  # Convert to tensor with shape (1, H, W)\n",
    "            masks.append(mask_tensor)\n",
    "\n",
    "        # Concatenate masks along the channel dimension\n",
    "        masks_tensor = torch.cat(masks, dim=0)  # Shape: (N, H, W), where N is the number of masks\n",
    "\n",
    "        # Compute the intersection of the masks\n",
    "        intersection_mask = torch.all(masks_tensor.bool(), dim=0).float()  # Shape: (H, W)\n",
    "\n",
    "        # Apply the intersection mask to the image\n",
    "        processed_image = image_tensor * intersection_mask.unsqueeze(0)  # Broadcasting to match image shape\n",
    "\n",
    "        # Save the processed image\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        save_path = os.path.join(output_dir, f\"{base_name}_processed.png\")\n",
    "        processed_image_np = processed_image.permute(1, 2, 0).numpy() * 255  # Convert to HWC and scale to 0-255\n",
    "        cv2.imwrite(save_path, processed_image_np.astype(np.uint8))\n",
    "        print(f\"Processed and saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "# Dataset Directories\n",
    "dataset_dir = \"Augmented_data\"\n",
    "output_dir = \"Intersection_data\"\n",
    "categories = ['normal', 'benign', 'malignant']\n",
    "\n",
    "# Create output directories for each category\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(output_dir, category), exist_ok=True)\n",
    "\n",
    "# Process images and masks\n",
    "for category in categories:\n",
    "    category_dir = os.path.join(dataset_dir, category)\n",
    "    output_category_dir = os.path.join(output_dir, category)\n",
    "\n",
    "    for file_name in os.listdir(category_dir):\n",
    "        if '_mask' not in file_name:  # Find the base image\n",
    "            image_path = os.path.join(category_dir, file_name)\n",
    "\n",
    "            # Collect corresponding masks\n",
    "            base_name = os.path.splitext(file_name)[0]\n",
    "            mask_paths = [os.path.join(category_dir, f) for f in os.listdir(category_dir)\n",
    "                          if base_name in f and '_mask' in f]\n",
    "\n",
    "            if mask_paths:  # Only process if there are masks\n",
    "                process_image_and_masks(image_path, mask_paths, output_category_dir, target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Visualizing Weighted Intersection and Corrected Regions with Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weighted_intersection(image_path, mask_paths, target_size=(224, 224), weight_threshold=0.3, output_dir=\"./corrected_intersections\"):\n",
    "    \"\"\"\n",
    "    Visualize the weighted intersection process of an image and its corresponding mask(s) with fallback.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        mask_paths (list of str): List of paths to the masks corresponding to the image.\n",
    "        target_size (tuple): Target size for resizing images and masks (width, height).\n",
    "        weight_threshold (float): Minimum weight sum to retain a pixel in the weighted mask.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the results at each step.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure image is RGB\n",
    "    image_resized = image.resize(target_size)  # Resize to target size\n",
    "    image_tensor = ToTensor()(image_resized)  # Convert to tensor with shape (3, H, W)\n",
    "\n",
    "    # Load the masks\n",
    "    masks = []\n",
    "    for mask_path in mask_paths:\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Ensure mask is grayscale\n",
    "        mask_resized = mask.resize(target_size)  # Resize to target size\n",
    "        mask_tensor = ToTensor()(mask_resized)  # Convert to tensor with shape (1, H, W)\n",
    "        masks.append(mask_tensor)\n",
    "\n",
    "    # Concatenate masks along the channel dimension\n",
    "    masks_tensor = torch.cat(masks, dim=0)  # Shape: (N, H, W), where N is the number of masks\n",
    "\n",
    "    # Compute the weighted intersection of the masks\n",
    "    weighted_mask = masks_tensor.mean(dim=0)  # Compute the average pixel intensity across masks\n",
    "    thresholded_mask = (weighted_mask > weight_threshold).float()  # Retain pixels above the threshold\n",
    "\n",
    "    # If the thresholded mask is empty, use the union of masks as fallback\n",
    "    if thresholded_mask.sum() == 0:\n",
    "        thresholded_mask = (masks_tensor.sum(dim=0) > 0).float()  # Union of masks (logical OR)\n",
    "\n",
    "    # Apply the intersection mask to the image\n",
    "    intersection_applied = image_tensor * thresholded_mask.unsqueeze(0)  # Broadcasting to match image shape\n",
    "\n",
    "    # Plot and visualize\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(1, len(masks) + 3, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image_resized)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    for i, mask_tensor in enumerate(masks):\n",
    "        plt.subplot(1, len(masks) + 3, i + 2)\n",
    "        plt.title(f\"Mask {i+1}\")\n",
    "        plt.imshow(mask_tensor.squeeze(0), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, len(masks) + 3, len(masks) + 2)\n",
    "    plt.title(\"Weighted Intersection Mask\")\n",
    "    plt.imshow(thresholded_mask, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, len(masks) + 3, len(masks) + 3)\n",
    "    plt.title(\"Intersection Applied\")\n",
    "    plt.imshow(intersection_applied.permute(1, 2, 0).numpy())\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "        # Save the processed image\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    save_path = os.path.join(output_dir, f\"{base_name}_corrected.png\")\n",
    "    processed_image_np = intersection_applied.permute(1, 2, 0).numpy() * 255  # Convert to HWC and scale to 0-255\n",
    "    cv2.imwrite(save_path, processed_image_np.astype(np.uint8))\n",
    "    print(f\"Processed and saved corrected image: {save_path}\")\n",
    "\n",
    "# Example usage\n",
    "image_path = \"Augmented_data/benign/benign (195).png\"  # Replace with actual image path\n",
    "mask_paths = [\n",
    "    \"Augmented_data/benign/benign (195)_mask.png\",\n",
    "    \"Augmented_data/benign/benign (195)_mask_1.png\",\n",
    "    \"Augmented_data/benign/benign (195)_mask_2.png\"\n",
    "]  # Replace with actual mask paths\n",
    "visualize_weighted_intersection(image_path, mask_paths, target_size=(224, 224), weight_threshold=0.3, output_dir=\"./corrected_intersections\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Organizing and Renaming Corrected Files in Intersection Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "corrected_dir = \"corrected_intersections\"\n",
    "intersection_dir = \"Intersection_data\"\n",
    "\n",
    "# Process corrected files\n",
    "for root, dirs, files in os.walk(corrected_dir):\n",
    "    for file in files:\n",
    "        # Full path to the corrected file\n",
    "        corrected_file_path = os.path.join(root, file)\n",
    "        \n",
    "        # Determine the category (e.g., normal, benign, malignant)\n",
    "        relative_path = os.path.relpath(root, corrected_dir)\n",
    "        category = relative_path.split(os.sep)[0]\n",
    "        \n",
    "        # Define the target directory in the intersection data folder\n",
    "        target_dir = os.path.join(intersection_dir, category)\n",
    "        os.makedirs(target_dir, exist_ok=True)  # Ensure the directory exists\n",
    "        \n",
    "        # Append \"_processed\" to the file name\n",
    "        base_name = os.path.splitext(file)[0]  # Get the file name without extension\n",
    "        new_file_name = f\"{base_name}_processed.png\"  # Append \"_processed\"\n",
    "        \n",
    "        # Full path for the new file in the target directory\n",
    "        target_file_path = os.path.join(target_dir, new_file_name)\n",
    "        \n",
    "        # Remove existing file in the target directory if it has the same name\n",
    "        if os.path.exists(target_file_path):\n",
    "            os.remove(target_file_path)\n",
    "            print(f\"Removed existing file: {target_file_path}\")\n",
    "        \n",
    "        # Move and rename the corrected file\n",
    "        shutil.move(corrected_file_path, target_file_path)\n",
    "        print(f\"Moved and renamed: {corrected_file_path} -> {target_file_path}\")\n",
    "\n",
    "print(\"All corrected files have been processed, renamed, and moved to the correct directories.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Center Cropping and Resizing Tumor Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "def center_crop_image(image_path, output_dir, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Center crop an intersection image to make the tumor region central.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input intersection image.\n",
    "        output_dir (str): Directory to save the cropped and resized images.\n",
    "        target_size (tuple): Target size for resizing images (width, height).\n",
    "\n",
    "    Returns:\n",
    "        None: Saves the cropped and resized image.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure image is RGB\n",
    "\n",
    "    # Convert image to a NumPy array to find the bounding box\n",
    "    image_array = np.array(image.convert(\"L\"))  # Convert to grayscale for processing\n",
    "    y_indices, x_indices = np.where(image_array > 0)  # Non-zero pixels in the image (tumor region)\n",
    "\n",
    "    if len(x_indices) == 0 or len(y_indices) == 0:\n",
    "        print(f\"Warning: No non-zero region found in {image_path}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Calculate bounding box of the tumor region\n",
    "    x_min, x_max = x_indices.min(), x_indices.max()\n",
    "    y_min, y_max = y_indices.min(), y_indices.max()\n",
    "\n",
    "    # Calculate the center and size of the bounding box\n",
    "    x_center = (x_min + x_max) // 2\n",
    "    y_center = (y_min + y_max) // 2\n",
    "\n",
    "    # Define cropping box to center the tumor region\n",
    "    crop_size = min(image.size)  # Use the smaller dimension of the image as the crop size\n",
    "    left = max(0, x_center - crop_size // 2)\n",
    "    top = max(0, y_center - crop_size // 2)\n",
    "    right = min(image.size[0], left + crop_size)\n",
    "    bottom = min(image.size[1], top + crop_size)\n",
    "\n",
    "    # Perform cropping\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "\n",
    "    # Resize the cropped image to the target size\n",
    "    resized_image = cropped_image.resize(target_size, Image.BILINEAR)\n",
    "\n",
    "    # Save the processed image\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    save_path = os.path.join(output_dir, f\"{base_name}_centered.png\")\n",
    "    resized_image.save(save_path)\n",
    "    print(f\"Processed and saved: {save_path}\")\n",
    "\n",
    "# Dataset Directories\n",
    "intersection_dir = \"Intersection_data\"\n",
    "output_dir = \"Cropped_intersection_data\"\n",
    "categories = ['normal', 'benign', 'malignant']\n",
    "\n",
    "# Create output directories for each category\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(output_dir, category), exist_ok=True)\n",
    "\n",
    "# Process images\n",
    "for category in categories:\n",
    "    category_dir = os.path.join(intersection_dir, category)\n",
    "    output_category_dir = os.path.join(output_dir, category)\n",
    "\n",
    "    for file_name in os.listdir(category_dir):\n",
    "        image_path = os.path.join(category_dir, file_name)\n",
    "        center_crop_image(image_path, output_category_dir, target_size=(224, 224))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
